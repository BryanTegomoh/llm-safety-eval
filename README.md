# LLM Safety Benchmark Processing

Data processing utilities for the AgentHarm benchmark dataset.

## Source

Based on [AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents](https://arxiv.org/abs/2410.09024) by Andriushchenko et al., 2024.

**Original dataset:** https://huggingface.co/datasets/ai-safety-institute/AgentHarm

## Contents

- `convert_to_csv.py` - JSON to CSV conversion utility
- `make_csv.py` - Streamlined CSV generation
- CSV exports of benchmark behaviors (harmful, benign, chat variants)

## License

Original benchmark: MIT License with additional safety research clause (see LICENSE)
